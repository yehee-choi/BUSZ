package com.example.cv2_project1

import android.content.Context
import android.graphics.Bitmap
import android.graphics.ImageFormat
import android.graphics.Rect
import android.graphics.YuvImage
import android.speech.tts.TextToSpeech
import android.util.Log
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.camera.view.PreviewView
import androidx.core.content.ContextCompat
import androidx.lifecycle.LifecycleOwner
import kotlinx.coroutines.*
import java.io.ByteArrayOutputStream
import java.util.concurrent.ExecutorService
import java.util.concurrent.Executors

class CameraManager(
    private val context: Context,
    private val lifecycleOwner: LifecycleOwner,
    private val previewView: PreviewView,
    private val textToSpeech: TextToSpeech
) {
    private val TAG = "CameraManager"

    private var cameraProvider: ProcessCameraProvider? = null
    private var imageAnalysis: ImageAnalysis? = null
    private var cameraExecutor: ExecutorService = Executors.newSingleThreadExecutor()

    // ê°ì²´ ê°ì§€ ë§¤ë‹ˆì €
    private var objectDetectionManager: ObjectDetectionManager? = null

    // ë¹„ë™ê¸° ê°ì§€ ì œì–´
    private val detectionScope = CoroutineScope(Dispatchers.Default + SupervisorJob())
    private var isDetectionRunning = false
    private val DETECTION_INTERVAL_MS = 3000L // 3ì´ˆ ê°„ê²©

    // í”„ë ˆì„ ì²˜ë¦¬ ì œì–´
    private var isProcessingFrame = false
    private var lastDetectionTime = 0L

    init {
        initializeObjectDetection()
    }

    private fun initializeObjectDetection() {
        objectDetectionManager = ObjectDetectionManager(
            context = context,
            textToSpeech = textToSpeech
        ) { detections ->
            // ê°ì§€ ê²°ê³¼ ì½œë°±
            Log.d(TAG, "ğŸ” ê°ì§€ëœ ê°ì²´: ${detections.size}ê°œ")

            val busCount = detections.count { it.label == "bus" }
            if (busCount > 0) {
                Log.d(TAG, "ğŸšŒ ë²„ìŠ¤ ${busCount}ê°œ ê°ì§€ë¨ - OCR ì§„í–‰ ì¤‘")
            }
        }
    }

    fun startCamera() {
        val cameraProviderFuture = ProcessCameraProvider.getInstance(context)

        cameraProviderFuture.addListener({
            try {
                cameraProvider = cameraProviderFuture.get()
                bindCameraUseCases()
                Log.d(TAG, "ğŸ“· ì¹´ë©”ë¼ ì‹œì‘ ì„±ê³µ")
            } catch (e: Exception) {
                Log.e(TAG, "ğŸ’¥ ì¹´ë©”ë¼ ì‹œì‘ ì‹¤íŒ¨", e)
            }
        }, ContextCompat.getMainExecutor(context))
    }

    private fun bindCameraUseCases() {
        val cameraProvider = this.cameraProvider ?: return

        // í”„ë¦¬ë·° ì„¤ì •
        val preview = Preview.Builder()
            .build()
            .also {
                it.setSurfaceProvider(previewView.surfaceProvider)
            }

        // ì´ë¯¸ì§€ ë¶„ì„ ì„¤ì •
        imageAnalysis = ImageAnalysis.Builder()
            .setTargetResolution(android.util.Size(640, 480))
            .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
            .build()
            .also { analysis ->
                analysis.setAnalyzer(cameraExecutor) { imageProxy ->
                    processImageProxy(imageProxy)
                }
            }

        // ì¹´ë©”ë¼ ì„ íƒ (í›„ë©´ ì¹´ë©”ë¼)
        val cameraSelector = CameraSelector.DEFAULT_BACK_CAMERA

        try {
            cameraProvider.unbindAll()

            cameraProvider.bindToLifecycle(
                lifecycleOwner,
                cameraSelector,
                preview,
                imageAnalysis
            )

        } catch (e: Exception) {
            Log.e(TAG, "ğŸ’¥ ì¹´ë©”ë¼ ë°”ì¸ë”© ì‹¤íŒ¨", e)
        }
    }

    // ğŸš€ ë¹„ë™ê¸° ê°ì²´ ê°ì§€ ì‹œì‘ (ë…ë¦½ì ì¸ ìŠ¤ë ˆë“œ)
    fun startAsyncObjectDetection() {
        if (isDetectionRunning) {
            Log.d(TAG, "ğŸ” ê°ì²´ ê°ì§€ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        }

        isDetectionRunning = true
        lastDetectionTime = 0L

        detectionScope.launch {
            Log.d(TAG, "ğŸš€ ë¹„ë™ê¸° ê°ì²´ ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘ (${DETECTION_INTERVAL_MS/1000}ì´ˆ ê°„ê²©)")

            while (isDetectionRunning) {
                try {
                    delay(DETECTION_INTERVAL_MS)

                    val currentTime = System.currentTimeMillis()
                    Log.d(TAG, "â° ê°ì²´ ê°ì§€ ì£¼ê¸° ë„ë‹¬ - ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬ í—ˆìš©")

                    // í”„ë ˆì„ ì²˜ë¦¬ í—ˆìš©
                    isProcessingFrame = false

                } catch (e: CancellationException) {
                    Log.d(TAG, "ğŸ” ê°ì²´ ê°ì§€ ìŠ¤ë ˆë“œ ì·¨ì†Œë¨")
                    break
                } catch (e: Exception) {
                    Log.e(TAG, "ğŸ’¥ ê°ì²´ ê°ì§€ ìŠ¤ë ˆë“œ ì˜¤ë¥˜", e)
                    delay(1000) // ì—ëŸ¬ ì‹œ 1ì´ˆ ëŒ€ê¸°
                }
            }

            Log.d(TAG, "ğŸ” ë¹„ë™ê¸° ê°ì²´ ê°ì§€ ìŠ¤ë ˆë“œ ì¢…ë£Œ")
        }

        // TTS ì‹œì‘ ì•ˆë‚´
        try {
            textToSpeech.speak(
                "3ì´ˆë§ˆë‹¤ ê°ì²´ ê°ì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤",
                TextToSpeech.QUEUE_ADD,
                null,
                "detection_start"
            )
        } catch (e: Exception) {
            Log.e(TAG, "TTS ì˜¤ë¥˜", e)
        }
    }

    private fun processImageProxy(imageProxy: ImageProxy) {
        val currentTime = System.currentTimeMillis()

        // ê°ì§€ ì£¼ê¸° ì œì–´
        if (isProcessingFrame || (currentTime - lastDetectionTime < DETECTION_INTERVAL_MS)) {
            imageProxy.close()
            return
        }

        try {
            val bitmap = imageProxyToBitmap(imageProxy)

            if (bitmap != null) {
                isProcessingFrame = true
                lastDetectionTime = currentTime

                Log.d(TAG, "ğŸ” ê°ì²´ ê°ì§€ ì‹¤í–‰ ì¤‘... (${DETECTION_INTERVAL_MS/1000}ì´ˆ ê°„ê²©)")

                // ë³„ë„ ì½”ë£¨í‹´ì—ì„œ ê°ì²´ ê°ì§€ ì‹¤í–‰
                CoroutineScope(Dispatchers.IO).launch {
                    try {
                        val detections = objectDetectionManager?.detectObjects(bitmap)

                        detections?.let { detectionList ->
                            val busDetections = detectionList.filter { it.label == "bus" }
                            if (busDetections.isNotEmpty()) {
                                Log.d(TAG, "ğŸšŒ ë²„ìŠ¤ ê°ì§€ ì™„ë£Œ - ${busDetections.size}ëŒ€")
                            } else {
                                Log.d(TAG, "ğŸ” ê°ì²´ ê°ì§€ ì™„ë£Œ - ë²„ìŠ¤ ì—†ìŒ (ì¼ë°˜ ê°ì²´: ${detectionList.size}ê°œ)")
                            }
                        }

                    } catch (e: Exception) {
                        Log.e(TAG, "ğŸ’¥ ê°ì²´ ê°ì§€ ì‹¤í–‰ ì‹¤íŒ¨", e)
                    } finally {
                        Log.d(TAG, "âœ… ê°ì²´ ê°ì§€ ì™„ë£Œ - ë‹¤ìŒ ê°ì§€ê¹Œì§€ ${DETECTION_INTERVAL_MS/1000}ì´ˆ ëŒ€ê¸°")
                    }
                }
            }

        } catch (e: Exception) {
            Log.e(TAG, "ğŸ’¥ í”„ë ˆì„ ë¶„ì„ ì‹¤íŒ¨", e)
            isProcessingFrame = false
        } finally {
            imageProxy.close()
        }
    }

    private fun imageProxyToBitmap(imageProxy: ImageProxy): Bitmap? {
        return try {
            val yBuffer = imageProxy.planes[0].buffer
            val vuBuffer = imageProxy.planes[2].buffer

            val ySize = yBuffer.remaining()
            val vuSize = vuBuffer.remaining()

            val nv21 = ByteArray(ySize + vuSize)

            yBuffer.get(nv21, 0, ySize)
            vuBuffer.get(nv21, ySize, vuSize)

            val yuvImage = YuvImage(nv21, ImageFormat.NV21, imageProxy.width, imageProxy.height, null)
            val out = ByteArrayOutputStream()
            yuvImage.compressToJpeg(Rect(0, 0, yuvImage.width, yuvImage.height), 75, out)
            val imageBytes = out.toByteArray()

            android.graphics.BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.size)

        } catch (e: Exception) {
            Log.e(TAG, "ğŸ’¥ Bitmap ë³€í™˜ ì‹¤íŒ¨", e)

            // ëŒ€ì•ˆ: ê°„ë‹¨í•œ RGB ë³€í™˜
            try {
                val bitmap = Bitmap.createBitmap(
                    imageProxy.width,
                    imageProxy.height,
                    Bitmap.Config.ARGB_8888
                )

                val yBuffer = imageProxy.planes[0].buffer
                val yPixelStride = imageProxy.planes[0].pixelStride
                val yRowStride = imageProxy.planes[0].rowStride

                val pixels = IntArray(imageProxy.width * imageProxy.height)
                var pixelIndex = 0

                for (y in 0 until imageProxy.height) {
                    for (x in 0 until imageProxy.width) {
                        val yIndex = y * yRowStride + x * yPixelStride
                        if (yIndex < yBuffer.capacity()) {
                            val yValue = yBuffer.get(yIndex).toInt() and 0xFF
                            val grayValue = yValue
                            val rgb = (0xFF shl 24) or (grayValue shl 16) or (grayValue shl 8) or grayValue
                            pixels[pixelIndex++] = rgb
                        }
                    }
                }

                bitmap.setPixels(pixels, 0, imageProxy.width, 0, 0, imageProxy.width, imageProxy.height)
                bitmap

            } catch (e2: Exception) {
                Log.e(TAG, "ğŸ’¥ ëŒ€ì•ˆ Bitmap ë³€í™˜ë„ ì‹¤íŒ¨", e2)
                null
            }
        }
    }

    fun stopCamera() {
        isDetectionRunning = false
        cameraProvider?.unbindAll()
        Log.d(TAG, "ğŸ“· ì¹´ë©”ë¼ ì¤‘ì§€")
    }

    fun pauseDetection() {
        isDetectionRunning = false
        Log.d(TAG, "â¸ï¸ ê°ì²´ ê°ì§€ ì¼ì‹œì •ì§€")
    }

    fun resumeDetection() {
        if (!isDetectionRunning) {
            startAsyncObjectDetection()
            Log.d(TAG, "â–¶ï¸ ê°ì²´ ê°ì§€ ì¬ì‹œì‘")
        }
    }

    fun cleanup() {
        isDetectionRunning = false
        detectionScope.cancel()
        cameraExecutor.shutdown()
        objectDetectionManager?.cleanup()
        cameraProvider?.unbindAll()
        Log.d(TAG, "ğŸ§¹ CameraManager ì •ë¦¬ ì™„ë£Œ")
    }
}